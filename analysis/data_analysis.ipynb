{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76286865",
   "metadata": {},
   "source": [
    "# Statistical Analysis: NHST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ff394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import analysis_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eba136",
   "metadata": {},
   "source": [
    "Load data from all `../res` sub-directories (treatments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d992f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dfs = {}    # dict to store statistical summary data (<session_name>.json)\n",
    "all_data_dfs = {}   # dict to store all individual measurements (all_data_<session_name>.json)\n",
    "\n",
    "experiment_data_dir = '../res' # directory generated by \"eval.py\", contains the .json files with the experiment data\n",
    "\n",
    "iteration_structure = True # flag to set the directory structure of the input data\n",
    "\n",
    "# Load all the experiment data\n",
    "summary_dfs, all_data_dfs = utils.load_experiment_data(experiment_data_dir, iteration_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ec49c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   data_path  prevalence    n  tp   tn  fp  \\\n",
      "0  ./out/MIS_AWQ_BTHS/2025-04-28/22_58_14/01    0.166667  120   2  100   0   \n",
      "1  ./out/MIS_AWQ_BTHS/2025-04-28/22_58_14/02    0.166667  120   2  100   0   \n",
      "2  ./out/MIS_AWQ_BTHS/2025-04-28/22_58_14/03    0.166667  120   2  100   0   \n",
      "3  ./out/MIS_AWQ_BTHS/2025-04-28/22_58_14/04    0.166667  120   1  100   0   \n",
      "4  ./out/MIS_AWQ_BTHS/2025-04-28/22_58_14/05    0.166667  120   1  100   0   \n",
      "\n",
      "   fn  accuracy  balanced_accuracy        f1  recall  precision  specificity  \\\n",
      "0  18  0.850000           0.923729  0.181818    0.10        1.0     0.847458   \n",
      "1  18  0.850000           0.923729  0.181818    0.10        1.0     0.847458   \n",
      "2  18  0.850000           0.923729  0.181818    0.10        1.0     0.847458   \n",
      "3  19  0.841667           0.920168  0.095238    0.05        1.0     0.840336   \n",
      "4  19  0.841667           0.920168  0.095238    0.05        1.0     0.840336   \n",
      "\n",
      "   err  time_to_analyze                                                GPU  \\\n",
      "0    0         7.775839  {'utilization': {'avg': 5.454545454545454, 'st...   \n",
      "1    0         7.728309  {'utilization': {'avg': 4.257575757575758, 'st...   \n",
      "2    0         7.822561  {'utilization': {'avg': 7.03030303030303, 'std...   \n",
      "3    0         7.461443  {'utilization': {'avg': 6.090909090909091, 'st...   \n",
      "4    0         7.549929  {'utilization': {'avg': 6.878787878787879, 'st...   \n",
      "\n",
      "                                                VRAM  \n",
      "0  {'max_consumed_MiB': 3737.0, 'utilization': {'...  \n",
      "1  {'max_consumed_MiB': 3737.0, 'utilization': {'...  \n",
      "2  {'max_consumed_MiB': 3737.0, 'utilization': {'...  \n",
      "3  {'max_consumed_MiB': 3737.0, 'utilization': {'...  \n",
      "4  {'max_consumed_MiB': 3737.0, 'utilization': {'...  \n"
     ]
    }
   ],
   "source": [
    "#print(summary_dfs[\"MIS_AWQ_ENCO\"])\n",
    "#print(all_data_dfs[\"MIS_AWQ_ENCO\"])\n",
    "print(all_data_dfs[\"MIS_AWQ_BTHS\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d62f67",
   "metadata": {},
   "source": [
    "### Flatten GPU and VRAM columns \n",
    "These contains nested objects and values.\n",
    "We are only interested in a subset of the contained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "392db5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_gpu_vram_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # TODO: fix the key for extracting \"vram_max_usage_mib\" from \"max_consumed_MiB\" -> new format (check repo)\n",
    "    \n",
    "    # GPU columns\n",
    "    df[\"gpu_util_mean\"] = df[\"GPU\"].apply(lambda x: x[\"utilization\"][\"avg\"] if isinstance(x, dict) else None)\n",
    "    df[\"gpu_util_max\"]  = df[\"GPU\"].apply(lambda x: x[\"utilization\"][\"max\"] if isinstance(x, dict) else None)\n",
    "\n",
    "    # VRAM columns\n",
    "    df[\"vram_util_mean\"]     = df[\"VRAM\"].apply(lambda x: x[\"utilization\"][\"avg\"] if isinstance(x, dict) else None)\n",
    "    df[\"vram_util_max\"]      = df[\"VRAM\"].apply(lambda x: x[\"utilization\"][\"max\"] if isinstance(x, dict) else None)\n",
    "    df[\"vram_max_usage_mib\"] = df[\"VRAM\"].apply(lambda x: x[\"max_consumed_MiB\"] if isinstance(x, dict) else None) # TODO: FIX KEY\n",
    "\n",
    "    # Drop the redundant columns\n",
    "    df = df.drop(columns=[\"GPU\", \"VRAM\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c288f3c",
   "metadata": {},
   "source": [
    "### Convert data to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_dfs_to_long(dictionary_dataframes: dict[pd.DataFrame], metrics_of_interest: list[str]) -> pd.DataFrame:\n",
    "    rows = [] # Temporary list to hold all constructed rows of data\n",
    "\n",
    "    # Iterate through each treatment and corresponding data\n",
    "    for treatment_name, df in dictionary_dataframes.items():\n",
    "\n",
    "        # Extract the treatment factors (dataset is a blocked variable)\n",
    "        model, quant, dataset = treatment_name.split(\"_\")\n",
    "        \n",
    "        for i, row in df.iterrows():\n",
    "            # Extract iteration from last dir in data_path (e.g. \"01\" from \".../01\", etc.)\n",
    "            match = re.search(r\"/(\\d{2})$\", row[\"data_path\"])\n",
    "            iteration = int(match.group(1)) if match else i + 1 # TODO: should we include the fallback or let it fail?\n",
    "\n",
    "            # Construct row dictionary\n",
    "            row_data = {\n",
    "                \"treatment\": treatment_name,\n",
    "                \"model\": model, \n",
    "                \"quantization\": quant, \n",
    "                \"dataset\": dataset,\n",
    "                \"iteration\": iteration\n",
    "            }\n",
    "        \n",
    "            # Add relevant metrics\n",
    "            for metric in metrics_of_interest:\n",
    "                row_data[metric] = row[metric]\n",
    "\n",
    "            rows.append(row_data)\n",
    "\n",
    "    # Combine all the rows of data into a single long-format dataframe\n",
    "    long_dataframe: pd.DataFrame = pd.DataFrame(rows)\n",
    "\n",
    "    return long_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e09809",
   "metadata": {},
   "source": [
    "### Flatten columns and convert to long format to prepare for NHST analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26ba74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      treatment model quantization dataset  iteration  accuracy  recall  \\\n",
      "0  MIS_AWQ_BTHS   MIS          AWQ    BTHS          1  0.850000    0.10   \n",
      "1  MIS_AWQ_BTHS   MIS          AWQ    BTHS          2  0.850000    0.10   \n",
      "2  MIS_AWQ_BTHS   MIS          AWQ    BTHS          3  0.850000    0.10   \n",
      "3  MIS_AWQ_BTHS   MIS          AWQ    BTHS          4  0.841667    0.05   \n",
      "4  MIS_AWQ_BTHS   MIS          AWQ    BTHS          5  0.841667    0.05   \n",
      "\n",
      "   precision        f1  balanced_accuracy  specificity  \n",
      "0        1.0  0.181818           0.923729     0.847458  \n",
      "1        1.0  0.181818           0.923729     0.847458  \n",
      "2        1.0  0.181818           0.923729     0.847458  \n",
      "3        1.0  0.095238           0.920168     0.840336  \n",
      "4        1.0  0.095238           0.920168     0.840336  \n",
      "      treatment model quantization dataset  iteration  time_to_analyze  \\\n",
      "0  MIS_AWQ_BTHS   MIS          AWQ    BTHS          1         7.775839   \n",
      "1  MIS_AWQ_BTHS   MIS          AWQ    BTHS          2         7.728309   \n",
      "2  MIS_AWQ_BTHS   MIS          AWQ    BTHS          3         7.822561   \n",
      "3  MIS_AWQ_BTHS   MIS          AWQ    BTHS          4         7.461443   \n",
      "4  MIS_AWQ_BTHS   MIS          AWQ    BTHS          5         7.549929   \n",
      "\n",
      "   gpu_util_mean  gpu_util_max  vram_util_mean  vram_util_max  \\\n",
      "0       5.454545          87.0        2.696970           59.0   \n",
      "1       4.257576          83.0        1.939394           55.0   \n",
      "2       7.030303          82.0        3.242424           47.0   \n",
      "3       6.090909          66.0        3.045455           46.0   \n",
      "4       6.878788          83.0        3.666667           45.0   \n",
      "\n",
      "   vram_max_usage_mib  \n",
      "0              3737.0  \n",
      "1              3737.0  \n",
      "2              3737.0  \n",
      "3              3737.0  \n",
      "4              3737.0  \n"
     ]
    }
   ],
   "source": [
    "efficacy_metrics = [\n",
    "    \"accuracy\", \"recall\", \n",
    "    \"precision\", \"f1\",\n",
    "    \"balanced_accuracy\", \n",
    "    \"specificity\"\n",
    "]\n",
    "\n",
    "efficiency_metrics = [\n",
    "    \"time_to_analyze\",\n",
    "    \"gpu_util_mean\", \"gpu_util_max\",\n",
    "    \"vram_util_mean\", \"vram_util_max\",\n",
    "    \"vram_max_usage_mib\"\n",
    "]\n",
    "\n",
    "# Flatten and extract the relevant GPU and VRAM metrics into distinct columns (they are intially nested objects)\n",
    "flattened_dfs = {key: flatten_gpu_vram_columns(df) for key, df in all_data_dfs.items()}\n",
    "\n",
    "# Convert data to long format; group by research question\n",
    "long_df_efficacy = convert_dict_dfs_to_long(flattened_dfs, efficacy_metrics)\n",
    "long_df_efficiency = convert_dict_dfs_to_long(flattened_dfs, efficiency_metrics)\n",
    "\n",
    "# Sort the dataframes using custom ordering schemes\n",
    "# Note: we can apply custom schemes to all the sorting columns if needed\n",
    "sorting_order = [\"dataset\", \"iteration\", \"model\", \"quantization\"]\n",
    "quant_order = [\"NONE\", \"AWQ\", \"GPTQ\", \"AQLM\"]\n",
    "#long_df_efficacy[\"quantization\"] = pd.Categorical(long_df_efficacy[\"quantization\"], categories=quant_order, ordered=True)\n",
    "#long_df_efficacy = long_df_efficacy.sort_values(by=sorting_order).reset_index(drop=True)\n",
    "\n",
    "print(long_df_efficacy.head())\n",
    "print(long_df_efficiency.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ceb859",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eedff3",
   "metadata": {},
   "source": [
    "## Testing ANOVA assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b4338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "234905a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      treatment model quantization dataset  iteration  accuracy  recall  \\\n",
      "0  MIS_AWQ_BTHS   MIS          AWQ    BTHS          1  0.850000    0.10   \n",
      "1  MIS_AWQ_BTHS   MIS          AWQ    BTHS          2  0.850000    0.10   \n",
      "2  MIS_AWQ_BTHS   MIS          AWQ    BTHS          3  0.850000    0.10   \n",
      "3  MIS_AWQ_BTHS   MIS          AWQ    BTHS          4  0.841667    0.05   \n",
      "4  MIS_AWQ_BTHS   MIS          AWQ    BTHS          5  0.841667    0.05   \n",
      "\n",
      "   precision        f1  balanced_accuracy  specificity  \n",
      "0        1.0  0.181818           0.923729     0.847458  \n",
      "1        1.0  0.181818           0.923729     0.847458  \n",
      "2        1.0  0.181818           0.923729     0.847458  \n",
      "3        1.0  0.095238           0.920168     0.840336  \n",
      "4        1.0  0.095238           0.920168     0.840336  \n"
     ]
    }
   ],
   "source": [
    "print(long_df_efficacy.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Enhanced REST-at)",
   "language": "python",
   "name": "my-new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
