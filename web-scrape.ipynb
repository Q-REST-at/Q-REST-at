{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "BASE_URL = \"https://www-archive.mozilla.org\"\n",
    "PAGE_URL_TEMPLATE = \"https://www-archive.mozilla.org/quality/browser/front-end/testcases/\"\n",
    "\n",
    "def scrape_test_page(page_url, req_counter, test_counter):\n",
    "\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    requirements = []\n",
    "    tests = []\n",
    "    mappings = []\n",
    "\n",
    "    def extract_section(soup, section_name):\n",
    "        h2 = soup.find(\"h2\", string=lambda text: text and section_name.lower() in text.lower())\n",
    "        content_text = \"\"\n",
    "        \n",
    "        if h2:\n",
    "            next_elem = h2.find_next_sibling()\n",
    "            parts = []\n",
    "            while next_elem and not (next_elem.name == 'h2'):\n",
    "                parts.append(next_elem.get_text(separator=' ', strip=True))\n",
    "                next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "            content_text = \"\\n\".join(parts).strip()\n",
    "                    \n",
    "        return content_text\n",
    "\n",
    "\n",
    "    for row in soup.find_all(\"tr\"):\n",
    "        tds = row.find_all(\"td\")\n",
    "\n",
    "        if len(tds) == 3: \n",
    "            feature = tds[0].get_text(strip=True)\n",
    "            description = tds[1].get_text(strip=True)\n",
    "            link_tag = tds[2].find(\"a\")\n",
    "\n",
    "        relative_link = link_tag['href'] if link_tag else None\n",
    "        full_link = urljoin(BASE_URL, relative_link) if relative_link else \"\"\n",
    "        # Save Requirement\n",
    "        req_id = f\"{req_counter}\"\n",
    "        requirements.append({\n",
    "            \"ID\": req_id,\n",
    "            \"Feature\": feature,\n",
    "            \"Description\": description\n",
    "        })\n",
    "\n",
    "      \n",
    "        \n",
    "       \n",
    "        test_response = requests.get(full_link)\n",
    "        test_soup = BeautifulSoup(test_response.content, \"html.parser\")\n",
    "\n",
    "        # OPTION 1\n",
    "        # Find <h2>Purpose</h2> and next <p> if the section is structured as a table\n",
    "        purpose_h2 = test_soup.find(\"h2\", string=lambda text: text and \"Purpose\" in text)\n",
    "        \n",
    "        purpose_text = \"\"\n",
    "        steps_text = \"\" \n",
    "        test_steps_combined= \"\"\n",
    "        purpose_text = extract_section(test_soup, \"Purpose\")\n",
    "        initial_conditions = extract_section(test_soup, \"Initial Conditions\")\n",
    "        steps_text = extract_section(test_soup, \"Steps/Description\")\n",
    "        expected_results = extract_section(test_soup, \"Expected Results\")\n",
    "\n",
    "\n",
    "        test_steps_combined = \"\\n\\n\".join(filter(None, [\n",
    "            initial_conditions,\n",
    "            steps_text,\n",
    "            expected_results\n",
    "        ]))\n",
    "\n",
    "        # Save Test\n",
    "        test_id = f\"{req_counter}\"\n",
    "        tests.append({\n",
    "            \"ID\": test_id,\n",
    "            \"Purpose\": purpose_text,\n",
    "            \"TestSteps\": test_steps_combined\n",
    "        })\n",
    "\n",
    "        # Save Mapping\n",
    "        mappings.append({\n",
    "            \"ReqID\": req_id,\n",
    "            \"TestID\": test_id\n",
    "        })\n",
    "\n",
    "        req_counter += 1\n",
    "        test_counter += 1\n",
    "\n",
    "    return requirements, tests, mappings, req_counter, test_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ead25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_requirements = []\n",
    "all_tests = []\n",
    "all_mappings = []\n",
    "\n",
    "TARGET_PATHS = [\n",
    "    \"bookmarks\",\n",
    "]\n",
    "\n",
    "req_counter = 1\n",
    "test_counter = 1\n",
    "\n",
    "for path in TARGET_PATHS:\n",
    "    page_url = urljoin(PAGE_URL_TEMPLATE, path)\n",
    "    reqs, tests, maps, req_counter, test_counter = scrape_test_page(page_url, req_counter, test_counter)\n",
    "    \n",
    "    all_requirements.extend(reqs)\n",
    "    all_tests.extend(tests)\n",
    "    all_mappings.extend(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ccc4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved: requirements.csv, tests.csv, mapping.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write to CSV files\n",
    "with open('data/Mozilla2/requirements.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['ID', 'Feature', 'Description'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_requirements)\n",
    "\n",
    "with open('data/Mozilla2/tests.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['ID', 'Purpose', 'TestSteps'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_tests)\n",
    "\n",
    "with open('data/Mozilla2/mapping.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['ReqID', 'TestID'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_mappings)\n",
    "\n",
    "print(\"Files saved: requirements.csv, tests.csv, mapping.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
